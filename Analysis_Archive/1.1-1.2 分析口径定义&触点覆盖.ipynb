{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以名爵为例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 分析口径定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-- Step 1: 圈出目标分析时间段的人的电话号码\n",
    "drop table if exists marketing_modeling.tmp_tp_analysis_users;\n",
    "create table marketing_modeling.tmp_tp_analysis_users as\n",
    "select \n",
    "    a.mobile\n",
    "from marketing_modeling.dw_mg_tp_ts_all_i a\n",
    "left join dtwarehouse.cdm_dim_dealer_employee_info b\n",
    "on a.mobile = b.mobile\n",
    "where b.mobile is null\n",
    "and a.action_time between '2020-06-01' and '2021-04-30'\n",
    "and a.mobile regexp '^[1][3-9][0-9]{9}$'\n",
    "group by a.mobile;\n",
    "\n",
    "-- Step 2: 圈出步骤一中圈出的人的相应时间段的行为\n",
    "drop table if exists marketing_modeling.tmp_tp_analysis_users;\n",
    "create table marketing_modeling.tmp_tp_convert_base as \n",
    "select \n",
    "a.*,\n",
    "ROW_NUMBER() OVER (PARTITION BY a.mobile ORDER BY action_time asc) action_rank\n",
    "from\n",
    "(\n",
    "    select \n",
    "        a.mobile, action_time, touchpoint_id    \n",
    "    from marketing_modeling.dw_mg_tp_ts_all_i a\n",
    "    left join marketing_modeling.tmp_tp_analysis_users b\n",
    "    on a.mobile = b.mobile\n",
    "    where b.mobile is not null\n",
    "    and touchpoint_id is not null and action_time is not null\n",
    "    and action_time <= '2021-06-20' and action_time >= '2020-01-01'\n",
    "    group by a.mobile, action_time, touchpoint_id\n",
    ") a\n",
    "\n",
    "-- Step 3: 考虑到运算速度，我们会把step2中生成的表拉取到本地存成csv，供后续的分析使用\n",
    "hive -e \"select  * from marketing_modeling.tmp_tp_convert_base\" > tp_analysis_base.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 触点覆盖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "names = ['mobile','action_time','touchpoint_id','action_rank']\n",
    "df = pd.read_csv('tp_analysis_base.csv',sep = '\\t', names = names)\n",
    "df['mobile'] = df['mobile'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id mapping, 获取触点名字\n",
    "id_mapping = pd.read_csv('data/id_mapping.csv')\n",
    "tp_name = {k:v for k,v in zip(id_mapping.touchpoint_id,id_mapping.touchpoint_name)}\n",
    "\n",
    "df = df.merge(id_mapping, on = 'touchpoint_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.1 用户触点总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先对每个用户经过的触点进行去重，之后计算每个用户经过的触点数量，此处不对触点行为时间做任何的限制\n",
    "cov_res = df[['mobile','touchpoint_id','touchpoint_name']].drop_duplicates()\\\n",
    ".groupby(by=['mobile'],as_index=False).agg({'touchpoint_id':'count'})\n",
    "\n",
    "# 按以下节点进行分箱\n",
    "bins = [-1,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,1000]\n",
    "cov_res['tp_vol'] = pd.cut(cov_res['touchpoint_id'],bins = bins)\n",
    "cov_res['tp_vol'] = cov_res['tp_vol'].astype(str)\n",
    "\n",
    "# 输出结果\n",
    "print(cov_res['tp_vol'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.2 人均触点总数、次数 —— By各触点大类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人均触点种数\n",
    "tp_cnt_dp = df[['mobile','touchpoint_id','level_1']].drop_duplicates()\\\n",
    ".groupby(by=['level_1'],as_index=False).agg({'touchpoint_id':'count'}).rename(columns= {'touchpoint_id':'uv'})\n",
    "\n",
    "tp_cnt_dp['tp_name'] = tp_cnt_dp.level_1.apply(lambda x:tp_name[x])\n",
    "tp_cnt_dp['avg_tp_type_cnt'] = tp_cnt_dp.uv / 2982100 #除以总人数\n",
    "\n",
    "# 人均触点次数\n",
    "tp_cnt = df[['mobile','touchpoint_id','level_1']]\\\n",
    ".groupby(by=['level_1'],as_index=False).agg({'touchpoint_id':'count'}).rename(columns= {'touchpoint_id':'pv'})\n",
    "\n",
    "tp_cnt['tp_name'] = tp_cnt.level_1.apply(lambda x:tp_name[x])\n",
    "tp_cnt['avg_tp_freq_cnt'] = tp_cnt.pv / 2982100 #除以总人数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3 第一至四层级的Top15高“覆盖度”、“活跃度”触点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_and_act(group_name,user_cnt):\n",
    "    # UV\n",
    "    uv_df = df[['mobile'] + [group_name]].drop_duplicates()\\\n",
    "    .groupby(by=[group_name],as_index=False).agg({'mobile':'count'}).rename(columns={'mobile':'uv'})\n",
    "\n",
    "    # PV\n",
    "    pv_df = df[['mobile'] + [group_name]]\\\n",
    "    .groupby(by=[group_name],as_index=False).agg({'mobile':'count'}).rename(columns={'mobile':'pv'})\n",
    "    \n",
    "    final_df = uv_df.merge(pv_df, on = group_name, how = 'left')\n",
    "    final_df['activity'] = final_df['pv'] * 1.0 / final_df['uv']\n",
    "    final_df['coverage'] = final_df['uv'] * 1.0 / user_cnt\n",
    "    \n",
    "    final_df.columns = ['touchpoint_id','uv','pv','activity','coverage']\n",
    "    final_df['touchpoint_name'] = final_df['touchpoint_id'].apply(lambda x:tp_name[x])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "cov_df = pd.DataFrame()\n",
    "for name in ['level_1','level_2','level_3','level_4']:\n",
    "    print('processing: ',name)\n",
    "    tmp_res = cov_and_act(name,2982100) #除以总人数\n",
    "    cov_df = cov_df.append(tmp_res)\n",
    "    \n",
    "print(cov_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
